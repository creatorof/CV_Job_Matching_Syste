{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pypdf2\n",
        "%pip install pdfplumber\n",
        "%pip install pymupdf\n",
        "%pip install langchain langchain-core langchain-community\n",
        "%pip install  langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud1jMfVlrDk2",
        "outputId": "83e04516-6f10-435c-b48e-46ffd6dab4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.8)\n",
            "Requirement already satisfied: pdfminer.six==20251107 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20251107)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.5)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (4.1.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.56.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.45.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.45.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.2->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Creating a PDF Extractor"
      ],
      "metadata": {
        "id": "cqWY0V-wrfiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV1AztPqq8Ed"
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import PyPDF2\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional\n",
        "\n",
        "class PDFParser:\n",
        "    \"\"\"Extract raw text from PDF files\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def extract_text_pdfplumber(self, pdf_path: Path) -> str:\n",
        "        \"\"\"Extract text using pdfplumber (better for tables)\"\"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                text = \"\"\n",
        "                for page in pdf.pages:\n",
        "                    text += page.extract_text() or \"\"\n",
        "                return text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error with pdfplumber: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text_pypdf2(self, pdf_path: Path) -> str:\n",
        "        \"\"\"Fallback: Extract text using PyPDF2\"\"\"\n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                text = \"\"\n",
        "                for page in reader.pages:\n",
        "                    text += page.extract_text() or \"\"\n",
        "                return text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error with PyPDF2: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text(self, pdf_path: Path) -> Dict[str, any]:\n",
        "        \"\"\"Main extraction method with fallback\"\"\"\n",
        "        pdf_path = Path(pdf_path)\n",
        "\n",
        "        if not pdf_path.exists():\n",
        "            raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n",
        "\n",
        "        text = self.extract_text_pdfplumber(pdf_path)\n",
        "\n",
        "        if not text or len(text) < 50:\n",
        "            text = self.extract_text_pypdf2(pdf_path)\n",
        "\n",
        "        if not text or len(text) < 50:\n",
        "            raise ValueError(f\"Failed to extract text from {pdf_path}\")\n",
        "\n",
        "        return {\n",
        "            \"filename\": pdf_path.name,\n",
        "            \"raw_text\": text,\n",
        "            \"text_length\": len(text),\n",
        "            \"success\": True\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = PDFParser()\n",
        "extracted_cv = parser.extract_text(\"Jillani Resume.pdf\")\n"
      ],
      "metadata": {
        "id": "LzBiWy1wrCrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Extracted {extracted_cv['text_length']} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRPqT_e9riWr",
        "outputId": "60ab9211-ba0c-4316-eaab-66228f579a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 13919 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uKWmXOqrraN",
        "outputId": "282b2669-5ec7-48d2-dae0-08995f18a17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'filename': 'Jillani Resume.pdf',\n",
              " 'raw_text': 'Muhammad Ghulam Jillani\\nLinkedIn | +92-321-1174167 | +92-321-1179584 | JillaniPortfolio.com | m.g.jillani123@gmail.com | Kaggle | GitHub | Medium\\nProfessional Summary __________________________________________________________________________________\\nSenior Data Scientist and Machine Learning Engineer specializing in Generative AI, LLMs, and Autonomous AI Systems, with a proven record\\nof transforming SaaS and PaaS platforms through innovative enterprise AI and agentic AI solutions. Expertise in optimizing workflows,\\nstreamlining data pipelines, and building scalable AI architectures to solve complex business challenges. Recognized as a 24x LinkedIn Top\\nVoice, Top 100 Global Kaggle Master, and KaggleX BIPOC Mentor, contributing to the NVIDIA Developer Program, Google Developer Group,\\nand AWS AI Community. Demonstrated leadership in AI-driven product innovation, LLMOps strategies, and multimodal AI, delivering impactful\\nresults with cutting-edge technologies across industries.\\nTechnical Skills __________________________________________________________________________________________\\nProgramming & Development:\\n• Languages & Frameworks: Python, Scikit-Learn, TensorFlow, Keras, PyTorch, NLTK, Hugging Face Transformers, OpenCV, FastAPI, Flask,\\nStreamlit.\\n• Tools & Libraries: Pandas, NumPy, Matplotlib, Plotly, Seaborn, PySpark, OpenAI API, REST APIs, GraphQL, Neo4j, Docker, GitHub Actions, CI/CD\\nPipelines.\\n• Database Systems: SQL, NoSQL, Vector Databases (Pinecone, Faiss, Chroma DB).\\nData Science & AI:\\n• Core Skills: Machine Learning, Deep Learning, Generative AI, LLMs (GPT, Gemini, LLaMA, Falcon,DeepSeek), Natural Language Processing (NLP),\\nTime Series Analysis, Model Deployment, Prompt Engineering.\\n• Frameworks & Tools: LangChain, RAG (Retrieval-Augmented Generation), LlamaIndex, LangGraph, LangGraph, PhiData, LangServer, AutoGen,\\nLangSmith, AutoML.\\n• Applications: AI-Driven Process Automation, Predictive Modeling, Statistical Analysis, Big Data Technologies, Data Visualization.\\nCloud & MLOps:\\n• Platforms: AWS (SageMaker, Lambda, Bedrock, EC2), Azure (Azure ML, Azure AI, App Services), GCP (Vertex AI, Cloud Functions), Heroku.\\n• Practices: MLOps, LLMOps, AIOps, Cloud Machine Learning, MLflow, Orchestration Frameworks.\\nManagement & Operations:\\n• Agile Methodologies, Microservices Architecture, Business Analysis, Product Management, Team Leadership, Stakeholder Management,\\nBusiness Intelligence.\\nCommunication & Collaboration:\\n• Strong in technical writing, effective communication, stakeholder engagement, and team collaboration, fostering a productive and inclusive\\nenvironment.\\nLanguages:\\n• Fluent in English and Urdu.\\nExperience ___________________________________________________________________________________________\\nSenior Data Scientist & Machine Learning Software Engineer (Generative AI) PURELOGICS\\nNew York, United States 12/2024 – Currently\\n• Led AI-Driven MVPs & Enterprise Deployments: Spearheaded high-impact MVP projects, including an Enterprise-Grade RAG Pipeline for BI, a\\nHealth Guard AI Pipeline for Remote Patient Monitoring, a GPT-4o-Based Conversational AI Chatbot, and an Agentic AI System for Legal & Financial\\nAdvisory, leveraging Generative AI, RAG, and Autonomous AI Agents.\\n• Scalable AI & Cloud Solutions: Designed, deployed, and optimized end-to-end AI/ML pipelines on AWS (SageMaker, Bedrock, Lambda)\\nand GCP (Vertex AI, BigQuery, Cloud Run), ensuring high availability, cost efficiency, and real-time insights.\\n• Advanced Multi-Agentic AI Architectures: Engineered multi-agent systems with LangChain, LangGraph, PhiData, Pinecone, and Graph\\nDBs to enhance automation, decision-making, and autonomous AI-driven workflows across domains.\\n• Leadership & Strategic Execution: Led cross-functional teams, aligning AI strategies with business objectives, optimizing LLMOps &\\nMLOps pipelines, and ensuring seamless model lifecycle management from development to production.\\n• Mentorship & Innovation: Mentored AI/ML teams, fostering expertise in LLM fine-tuning, Retrieval-Augmented Generation (RAG),\\nand AI-powered automation, while driving continuous innovation in GenAI applications.\\n• Key Achievements: Successfully delivered scalable, enterprise-grade AI solutions, exceeding performance benchmarks, accelerating\\ndeployment cycles, and enhancing efficiency, automation, and business intelligence.\\nSenior Data Scientist Machine Learning & Gen AI Engineer (Volunteer) NVIDIA\\nCalifornia, United States 08/2024 – Currently\\n• NVIDIA & Z by HP Developer Programs: Active member contributing to GPU-optimized applications and testing enterprise-level Generative AI\\nsolutions on NVIDIA AI Studio and Z by HP platforms.\\n• LLM Contributions: Developed and tested open-source and enterprise-level LLMs, including vLLMs, for Generative AI domains.\\n• Specialized SDK Integration: Leveraged cutting-edge NVIDIA tools and SDKs to build and optimize AI solutions.\\n• Collaborative Expertise: Worked closely with NVIDIA and Z by HP teams to validate and enhance AI tools and frameworks.\\n• Community Contributions: Actively contributed to open-source LLM projects, driving innovation in Generative AI and large-scale deployments.\\nSenior Data Scientist & Machine Learning Engineer BLOCBELT\\nMaryland, United States 12/2022 – 12/2024\\n• Strategic AI Leadership & Team Management: Led the development of AI-driven SaaS and PaaS solutions, managing a team of three, with a\\nfocus on Big Data, Data Analysis, and AI Engineering. This initiative enhanced operational efficiency, resulting in $2M in cost savings for clients.\\n• Sales Forecasting & Market Analysis: Improved sales forecasting accuracy by 80-90% through data analysis across 120+ market entities, leading\\nto actionable growth strategies and enhanced sales workflows.\\n• E-Commerce Platform Innovation & Sales Growth: Successfully launched a client-focused personalized fashion e-commerce platform featuring\\nan advanced recommendation engine. This initiative led to an 80% increase in sales and a 200% surge in online orders, surpassing project goals by\\nthree months ahead of schedule.• Operational Excellence & Cost Reduction: Streamlined data processing and optimized workflows using OpenCV, leading to significant cost\\nsavings and improved efficiency.\\n• Data-Driven Strategy & Revenue Growth: Led the development of statistical models and predictive analytics, resulting in an 18% increase in\\ncompany revenue. Enhanced data visibility by 45% with strategic dashboards, fostering cross-functional collaboration.\\n• AI Integration & Enhanced Digital Sales Experience: Integrated AI into SaaS and PaaS offerings, focusing on distributed systems and conducting\\nover 25 A/B tests to refine the e-commerce experience, driving technological advancements.\\nAI Data Scientist Kaggle Master Mentor (Part-Time, 20 hours/week) GOOGLE-KAGGLE\\nSan Francisco, USA 12/2022 – 11/2024\\n• Championed mentorship initiatives through the Kaggle-X BIPOC Mentorship Program, dedicating 20 hours weekly to guiding aspiring data\\nscientists in technical skill development and community contributions.\\n• Secured a position among the Top 100 Kaggle contributors globally, recognized as the first Pakistani mentor in the program.\\n• Led a team of four mentees, enhancing their skills in data science, machine learning, and real-world problem-solving.\\n• Drove innovation by collaborating on high-impact AI projects and actively contributing to the global data science community.\\nData Scientist Crypto-Express\\nThailand 01/2022 - 12/2022\\n• Developed an Anti-spoofing Face-App, enhancing digital identity security and reducing identity fraud by 70%.\\n• Applied AI and ML techniques to solve industry-critical issues, improving efficiency by 25% and reducing operational costs by 15%.\\n• Engineered predictive models and provided actionable insights, leading to a 20% revenue increase through data-driven decision-making.\\n• Advanced expertise in EDA, Machine Learning, and Deep Learning, saving over 250+ hours of manual analysis annually.\\n• Successfully deployed AI/ML projects remotely, adapting to dynamic conditions and gaining significant experience in the AI/ML field.\\nArtificial Intelligence Engineer Pakistan Freelancing Training Center\\nLahore, Pakistan 01/2021 - 12/2021\\n• Led AI and Data Science training sessions, preparing students to tackle real-world challenges.\\n• Designed and deployed models using TensorFlow and Keras, improving system efficiency and accuracy.\\n• Bridged the gap between academic learning and industry skills, driving practical applications of AI technologies.\\n• Automated repetitive data tasks using Python, significantly reducing manual labor and error rates.\\n• Engaged in ongoing AI research to apply cutting-edge methodologies to projects.\\nProjects _____________________________________________________________________________________________\\n• Health Assistance Application (LLM): Architected a comprehensive Health Assistance Application leveraging the Gemini 1.5 Pro LLM model, RAG,\\nand LangChain. This solution supports doctors and patients by providing detailed medical information, symptom diagnosis, treatment suggestio ns,\\nand preventive healthcare advice. The integration of generative AI ensures accurate and personalized health recommendations, significantly\\nenhancing patient care and medical consultations.\\n• AI-Powered Blog Generator (LLM): Developed an AI-powered content generator leveraging Llama 3.1 8B, AWS Bedrock, and RAG for real-time fine-\\ntuning on dynamic datasets. Integrated with Streamlit for a seamless user interface, the system automated blog creation, editing, and publishing,\\nincreasing efficiency in content marketing and engagement for enterprises.\\n• Conversational AI Chatbot for Customer Support (GPT-4o, LangChain, Bedrock): Designed and deployed an enterprise-grade chatbot powered by\\nGPT-4o, integrated with LangChain and AWS Bedrock. Implemented advanced NLP techniques such as intent recognition and dynamic response\\ngeneration, reducing customer query resolution times by 40% and improving customer satisfaction.\\n• AutoML-Studio: Built a low-code/no-code machine learning platform enabling rapid development and deployment of predictive models.\\nIncorporated MLflow for tracking, XAI (SHAP) for explainability, and data drift detection to ensure model reliability. Deployed with FastAPI and\\nStreamlit, the platform supports classification, regression, time-series forecasting and clustering, empowering non-technical users to build robust\\nAI solutions.\\n• DocuWiz AI (LLM): Engineered a document intelligence tool leveraging advanced NLP models like BART and DistilBERT for text extraction,\\nsummarization, and sentiment analysis. Integrated RAG and LLMs to enable detailed insights and visualizations for PDF and DOCX analysis. Deployed\\nas an interactive Streamlit application and FastAPI, reducing document processing time by 60% and enhancing productivity in legal and academic\\ndomains.\\n• Harvestify-AI-Powered-Plant-Health-Assistant: Designed and implemented an AI-driven application leveraging Azure AI Studio and Azure App\\nServices to diagnose plant leaf diseases through real-time image analysis. The system integrates deep learning models to recommend crops and\\nfertilizer solutions tailored to soil and weather conditions, enhancing agricultural decision-making. Deployed on Microsoft Azure, the solution\\nreduced disease detection time by 70%, improved crop yield predictions by 30%, and empowered farmers with actionable insights to optimize\\nproductivity and sustainability.\\n• Intelligent Document Summarization Tool (LLM): Developed an Intelligent Document Summarization Tool using transformer-based LLM models\\nlike Pegasus to generate concise summaries from lengthy documents while preserving key information. Deployed with FastAPI and Streamlit APP\\nfor real-time interaction, supporting formats like PDF and DOCX, and leveraging semantic analysis for relevance extraction. Reduced manual\\ndocument review time by 60%, boosting productivity in legal and academic workflows.\\n• Customer Satisfaction Prediction System (MLOps): Created a predictive analytics system using ZenML and MLflow within an MLOps framework to\\nachieve 93% accuracy in forecasting customer satisfaction. Streamlined pipeline management and deployed models efficiently, providing actionable\\ninsights that improved business decision-making and customer retention strategies.\\nEducation ______________________________________________________________________________________________\\nBachelor in Computer Science (Major: Artificial Intelligence and Computer Science) Institute of Management Sciences\\nCERTIFICATIONS_________________________________________________________________________________________\\n• IBM Machine Learning Specialization Professional Certificate, IBM. • Deep Learning Specialization, DeepLearning.ai.\\n• Microsoft Azure AI Fundamentals AI-900 Exam Prep Specialization, Microsoft. • Prompt Engineering for ChatGPT, Vanderbilt University.\\n• Machine Learning Engineering for Production (MLOps), DeepLearning.ai. • AI Product Management, Duke University.\\n• Generative Adversarial Networks (GANs) Specialization, DeepLearning.ai. • IBM Generative AI Product Managers, IBM.\\n• Preparing for Google Cloud Certification: Machine Learning Engineer, Google. • IBM AI Product Manager, IBM.\\n• AWS Cloud Solutions Architect Professional Certificate, Amazon Web Services. • Google Project Management: Professional Certificate, Google.\\n• Practical Data Science on the AWS Cloud Specialization, DeepLearning.ai. • Machine Learning Specialization, DeepLearning.AI.\\n• MLOps | Machine Learning Operations Specialization, Duke University. • Google Business Intelligence Professional Certificate, Google.\\n• Advanced Machine Learning on Google Cloud Specialization, Google Cloud. • Large Language Model Operations (LLMOps), Duke University.\\n• Google Advanced Data Analytics Professional Certificate, Google.',\n",
              " 'text_length': 13919,\n",
              " 'success': True}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setting up the extractor"
      ],
      "metadata": {
        "id": "NH3fhwfnrwqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Defining the Model for Resume Information"
      ],
      "metadata": {
        "id": "GQnjz4P9r2Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Dict\n",
        "import json"
      ],
      "metadata": {
        "id": "MZFJgDQgrtLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Location(BaseModel):\n",
        "    city: Optional[str] = None\n",
        "    countryCode: Optional[str] = None\n",
        "    region: Optional[str] = None\n",
        "\n",
        "class WorkExperience(BaseModel):\n",
        "    company: str\n",
        "    position: str\n",
        "    startDate: Optional[str] = None\n",
        "    endDate: Optional[str] = None\n",
        "    summary: Optional[str] = None\n",
        "    highlights: Optional[List[str]] = []\n",
        "\n",
        "class Education(BaseModel):\n",
        "    institution: str\n",
        "    degree: Optional[str] = None\n",
        "    field: Optional[str] = None\n",
        "    startDate: Optional[str] = None\n",
        "    endDate: Optional[str] = None\n",
        "    gpa: Optional[str] = None\n",
        "\n",
        "class CVData(BaseModel):\n",
        "    name: str = Field(description=\"Full name of the candidate\")\n",
        "    email: Optional[str] = Field(description=\"Email address\")\n",
        "    phone: Optional[str] = Field(description=\"Phone number\")\n",
        "    location: Optional[Location] = None\n",
        "    summary: Optional[str] = Field(description=\"Professional summary or objective\")\n",
        "    work: List[WorkExperience] = Field(default_factory=list)\n",
        "    education: List[Education] = Field(default_factory=list)\n",
        "    skills: List[str] = Field(default_factory=list)\n",
        "    languages: List[str] = Field(default_factory=list)\n",
        "    certifications: List[str] = Field(default_factory=list)\n",
        "    total_experience: float = Field(default_factory=float)"
      ],
      "metadata": {
        "id": "kXUcpm6qsKBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Creating the extractor"
      ],
      "metadata": {
        "id": "L74aWIihtfmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from google.colab import userdata\n",
        "import os\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "class CVExtractor:\n",
        "    \"\"\"LLM-based CV information extraction\"\"\"\n",
        "\n",
        "    def __init__(self, llm_model: str = \"models/gemini-2.5-flash-lite\"):\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=llm_model,\n",
        "            temperature=1.0,\n",
        "            max_tokens=None,\n",
        "            timeout=None,\n",
        "            max_retries=2,\n",
        "        )\n",
        "        self.parser = PydanticOutputParser(pydantic_object=CVData)\n",
        "\n",
        "        self.prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an expert CV/Resume parser. Extract structured information from resumes.\n",
        "            Be thorough but accurate. If information is not present, leave fields empty.\n",
        "\n",
        "            {format_instructions}\"\"\"),\n",
        "            (\"user\", \"Extract information from this CV:\\n\\n{cv_text}\")\n",
        "        ])\n",
        "\n",
        "    def extract(self, cv_text: str) -> Dict:\n",
        "        \"\"\"Extract structured data from CV text\"\"\"\n",
        "\n",
        "        chain = self.prompt | self.llm | self.parser\n",
        "\n",
        "        try:\n",
        "            result = chain.invoke({\n",
        "                \"cv_text\": cv_text,\n",
        "                \"format_instructions\": self.parser.get_format_instructions()\n",
        "            })\n",
        "\n",
        "            cv = result.model_dump()\n",
        "            cv['total_experience'] = self.total_experience(cv['work'])\n",
        "\n",
        "            return cv\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Extraction error: {e}\")\n",
        "            return self._fallback_extraction(cv_text)\n",
        "\n",
        "    def parse_date(self, date_str):\n",
        "      \"\"\"Parse date string into datetime object.\n",
        "        Supports MM/YYYY, YYYY-MM-DD, and 'Currently' or invalid strings.\"\"\"\n",
        "      if not date_str or date_str.strip().lower() in {\"currently\", \"present\"}:\n",
        "          return datetime.now()\n",
        "\n",
        "      for fmt in (\"%m/%Y\", \"%Y-%m-%d\", \"%d/%m/%Y\", \"%Y/%m/%d\"):\n",
        "          try:\n",
        "              return datetime.strptime(date_str, fmt)\n",
        "          except ValueError:\n",
        "              continue\n",
        "      # If all parsing fails, treat as None\n",
        "      return None\n",
        "\n",
        "    def total_experience(self, work_list):\n",
        "      \"\"\"Calculate total experience in years including days.\"\"\"\n",
        "      total_days = 0\n",
        "\n",
        "      for job in work_list:\n",
        "          start = self.parse_date(job.get(\"startDate\"))\n",
        "          end = self.parse_date(job.get(\"endDate\"))\n",
        "\n",
        "          if start and end:\n",
        "              delta = end - start\n",
        "              total_days += delta.days\n",
        "\n",
        "      # Convert days to years\n",
        "      total_years = total_days / 365.25  # accounts for leap years\n",
        "      return round(total_years, 2)\n",
        "\n",
        "    def _fallback_extraction(self, cv_text: str) -> Dict:\n",
        "        \"\"\"Simple fallback extraction\"\"\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"Extract CV information as JSON. Include name, email, phone, skills, work experience, education.\"},\n",
        "            {\"role\": \"user\", \"content\": cv_text}\n",
        "        ]\n",
        "\n",
        "        response = self.llm.invoke(messages)\n",
        "\n",
        "        try:\n",
        "            json_str = response.content.strip()\n",
        "            if \"```json\" in json_str:\n",
        "                json_str = json_str.split(\"```json\")[1].split(\"```\")[0]\n",
        "            return json.loads(json_str)\n",
        "        except:\n",
        "            return {\"name\": \"Unknown\", \"raw_text\": cv_text}\n"
      ],
      "metadata": {
        "id": "2mHNU2upsMSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = CVExtractor()\n",
        "cv_json = extractor.extract(extracted_cv)"
      ],
      "metadata": {
        "id": "lwwBRgCCsTaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(cv_json, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1ccGlRutz1W",
        "outputId": "b8c105e0-f032-468b-b4d7-6089e5c1b1e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Muhammad Ghulam Jillani\",\n",
            "  \"email\": \"m.g.jillani123@gmail.com\",\n",
            "  \"phone\": \"+92-321-1174167, +92-321-1179584\",\n",
            "  \"location\": {\n",
            "    \"city\": \"New York\",\n",
            "    \"countryCode\": \"US\",\n",
            "    \"region\": \"United States\"\n",
            "  },\n",
            "  \"summary\": \"Senior Data Scientist and Machine Learning Engineer specializing in Generative AI, LLMs, and Autonomous AI Systems, with a proven record\\nof transforming SaaS and PaaS platforms through innovative enterprise AI and agentic AI solutions. Expertise in optimizing workflows,\\nstreamlining data pipelines, and building scalable AI architectures to solve complex business challenges. Recognized as a 24x LinkedIn Top\\nVoice, Top 100 Global Kaggle Master, and KaggleX BIPOC Mentor, contributing to the NVIDIA Developer Program, Google Developer Group,\\nand AWS AI Community. Demonstrated leadership in AI-driven product innovation, LLMOps strategies, and multimodal AI, delivering impactful\\nresults with cutting-edge technologies across industries.\",\n",
            "  \"work\": [\n",
            "    {\n",
            "      \"company\": \"PURELOGICS\",\n",
            "      \"position\": \"Senior Data Scientist & Machine Learning Software Engineer (Generative AI)\",\n",
            "      \"startDate\": \"12/2024\",\n",
            "      \"endDate\": \"Currently\",\n",
            "      \"summary\": \"Led AI-Driven MVPs & Enterprise Deployments: Spearheaded high-impact MVP projects, including an Enterprise-Grade RAG Pipeline for BI, a\\nHealth Guard AI Pipeline for Remote Patient Monitoring, a GPT-4o-Based Conversational AI Chatbot, and an Agentic AI System for Legal & Financial\\nAdvisory, leveraging Generative AI, RAG, and Autonomous AI Agents.\\nScalable AI & Cloud Solutions: Designed, deployed, and optimized end-to-end AI/ML pipelines on AWS (SageMaker, Bedrock, Lambda)\\nand GCP (Vertex AI, BigQuery, Cloud Run), ensuring high availability, cost efficiency, and real-time insights.\\nAdvanced Multi-Agentic AI Architectures: Engineered multi-agent systems with LangChain, LangGraph, PhiData, Pinecone, and Graph\\nDBs to enhance automation, decision-making, and autonomous AI-driven workflows across domains.\\nLeadership & Strategic Execution: Led cross-functional teams, aligning AI strategies with business objectives, optimizing LLMOps &\\nMLOps pipelines, and ensuring seamless model lifecycle management from development to production.\\nMentorship & Innovation: Mentored AI/ML teams, fostering expertise in LLM fine-tuning, Retrieval-Augmented Generation (RAG),\\nand AI-powered automation, while driving continuous innovation in GenAI applications.\\nKey Achievements: Successfully delivered scalable, enterprise-grade AI solutions, exceeding performance benchmarks, accelerating\\ndeployment cycles, and enhancing efficiency, automation, and business intelligence.\",\n",
            "      \"highlights\": []\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"NVIDIA\",\n",
            "      \"position\": \"Senior Data Scientist Machine Learning & Gen AI Engineer (Volunteer)\",\n",
            "      \"startDate\": \"08/2024\",\n",
            "      \"endDate\": \"Currently\",\n",
            "      \"summary\": \"NVIDIA & Z by HP Developer Programs: Active member contributing to GPU-optimized applications and testing enterprise-level Generative AI\\nsolutions on NVIDIA AI Studio and Z by HP platforms.\\nLLM Contributions: Developed and tested open-source and enterprise-level LLMs, including vLLMs, for Generative AI domains.\\nSpecialized SDK Integration: Leveraged cutting-edge NVIDIA tools and SDKs to build and optimize AI solutions.\\nCollaborative Expertise: Worked closely with NVIDIA and Z by HP teams to validate and enhance AI tools and frameworks.\\nCommunity Contributions: Actively contributed to open-source LLM projects, driving innovation in Generative AI and large-scale deployments.\",\n",
            "      \"highlights\": []\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"BLOCBELT\",\n",
            "      \"position\": \"Senior Data Scientist & Machine Learning Engineer\",\n",
            "      \"startDate\": \"12/2022\",\n",
            "      \"endDate\": \"12/2024\",\n",
            "      \"summary\": \"Strategic AI Leadership & Team Management: Led the development of AI-driven SaaS and PaaS solutions, managing a team of three, with a\\nfocus on Big Data, Data Analysis, and AI Engineering. This initiative enhanced operational efficiency, resulting in $2M in cost savings for clients.\\nSales Forecasting & Market Analysis: Improved sales forecasting accuracy by 80-90% through data analysis across 120+ market entities, leading\\nto actionable growth strategies and enhanced sales workflows.\\nE-Commerce Platform Innovation & Sales Growth: Successfully launched a client-focused personalized fashion e-commerce platform featuring\\nan advanced recommendation engine. This initiative led to an 80% increase in sales and a 200% surge in online orders, surpassing project goals by\\nthree months ahead of schedule.\\u2022 Operational Excellence & Cost Reduction: Streamlined data processing and optimized workflows using OpenCV, leading to significant cost\\nsavings and improved efficiency.\\nData-Driven Strategy & Revenue Growth: Led the development of statistical models and predictive analytics, resulting in an 18% increase in\\ncompany revenue. Enhanced data visibility by 45% with strategic dashboards, fostering cross-functional collaboration.\\nAI Integration & Enhanced Digital Sales Experience: Integrated AI into SaaS and PaaS offerings, focusing on distributed systems and conducting\\nover 25 A/B tests to refine the e-commerce experience, driving technological advancements.\",\n",
            "      \"highlights\": []\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"GOOGLE-KAGGLE\",\n",
            "      \"position\": \"AI Data Scientist Kaggle Master Mentor (Part-Time, 20 hours/week)\",\n",
            "      \"startDate\": \"12/2022\",\n",
            "      \"endDate\": \"11/2024\",\n",
            "      \"summary\": \"Championed mentorship initiatives through the Kaggle-X BIPOC Mentorship Program, dedicating 20 hours weekly to guiding aspiring data\\nscientists in technical skill development and community contributions.\\nSecured a position among the Top 100 Kaggle contributors globally, recognized as the first Pakistani mentor in the program.\\nLed a team of four mentees, enhancing their skills in data science, machine learning, and real-world problem-solving.\\nDrove innovation by collaborating on high-impact AI projects and actively contributing to the global data science community.\",\n",
            "      \"highlights\": []\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Crypto-Express\",\n",
            "      \"position\": \"Data Scientist\",\n",
            "      \"startDate\": \"01/2022\",\n",
            "      \"endDate\": \"12/2022\",\n",
            "      \"summary\": \"Developed an Anti-spoofing Face-App, enhancing digital identity security and reducing identity fraud by 70%.\\nApplied AI and ML techniques to solve industry-critical issues, improving efficiency by 25% and reducing operational costs by 15%.\\nEngineered predictive models and provided actionable insights, leading to a 20% revenue increase through data-driven decision-making.\\nAdvanced expertise in EDA, Machine Learning, and Deep Learning, saving over 250+ hours of manual analysis annually.\\nSuccessfully deployed AI/ML projects remotely, adapting to dynamic conditions and gaining significant experience in the AI/ML field.\",\n",
            "      \"highlights\": []\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Pakistan Freelancing Training Center\",\n",
            "      \"position\": \"Artificial Intelligence Engineer\",\n",
            "      \"startDate\": \"01/2021\",\n",
            "      \"endDate\": \"12/2021\",\n",
            "      \"summary\": \"Led AI and Data Science training sessions, preparing students to tackle real-world challenges.\\nDesigned and deployed models using TensorFlow and Keras, improving system efficiency and accuracy.\\nBridged the gap between academic learning and industry skills, driving practical applications of AI technologies.\\nAutomated repetitive data tasks using Python, significantly reducing manual labor and error rates.\\nEngaged in ongoing AI research to apply cutting-edge methodologies to projects.\",\n",
            "      \"highlights\": []\n",
            "    }\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"institution\": \"Institute of Management Sciences\",\n",
            "      \"degree\": \"Bachelor\",\n",
            "      \"field\": \"Computer Science (Major: Artificial Intelligence and Computer Science)\",\n",
            "      \"startDate\": null,\n",
            "      \"endDate\": null,\n",
            "      \"gpa\": null\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"Scikit-Learn\",\n",
            "    \"TensorFlow\",\n",
            "    \"Keras\",\n",
            "    \"PyTorch\",\n",
            "    \"NLTK\",\n",
            "    \"Hugging Face Transformers\",\n",
            "    \"OpenCV\",\n",
            "    \"FastAPI\",\n",
            "    \"Flask\",\n",
            "    \"Streamlit\",\n",
            "    \"Pandas\",\n",
            "    \"NumPy\",\n",
            "    \"Matplotlib\",\n",
            "    \"Plotly\",\n",
            "    \"Seaborn\",\n",
            "    \"PySpark\",\n",
            "    \"OpenAI API\",\n",
            "    \"REST APIs\",\n",
            "    \"GraphQL\",\n",
            "    \"Neo4j\",\n",
            "    \"Docker\",\n",
            "    \"GitHub Actions\",\n",
            "    \"CI/CD Pipelines\",\n",
            "    \"SQL\",\n",
            "    \"NoSQL\",\n",
            "    \"Vector Databases (Pinecone, Faiss, Chroma DB)\",\n",
            "    \"Machine Learning\",\n",
            "    \"Deep Learning\",\n",
            "    \"Generative AI\",\n",
            "    \"LLMs (GPT, Gemini, LLaMA, Falcon,DeepSeek)\",\n",
            "    \"Natural Language Processing (NLP)\",\n",
            "    \"Time Series Analysis\",\n",
            "    \"Model Deployment\",\n",
            "    \"Prompt Engineering\",\n",
            "    \"LangChain\",\n",
            "    \"RAG (Retrieval-Augmented Generation)\",\n",
            "    \"LlamaIndex\",\n",
            "    \"LangGraph\",\n",
            "    \"PhiData\",\n",
            "    \"LangServer\",\n",
            "    \"AutoGen\",\n",
            "    \"LangSmith\",\n",
            "    \"AutoML\",\n",
            "    \"AI-Driven Process Automation\",\n",
            "    \"Predictive Modeling\",\n",
            "    \"Statistical Analysis\",\n",
            "    \"Big Data Technologies\",\n",
            "    \"Data Visualization\",\n",
            "    \"AWS (SageMaker, Lambda, Bedrock, EC2)\",\n",
            "    \"Azure (Azure ML, Azure AI, App Services)\",\n",
            "    \"GCP (Vertex AI, Cloud Functions)\",\n",
            "    \"Heroku\",\n",
            "    \"MLOps\",\n",
            "    \"LLMOps\",\n",
            "    \"AIOps\",\n",
            "    \"Cloud Machine Learning\",\n",
            "    \"MLflow\",\n",
            "    \"Orchestration Frameworks\",\n",
            "    \"Agile Methodologies\",\n",
            "    \"Microservices Architecture\",\n",
            "    \"Business Analysis\",\n",
            "    \"Product Management\",\n",
            "    \"Team Leadership\",\n",
            "    \"Stakeholder Management\",\n",
            "    \"Business Intelligence\",\n",
            "    \"technical writing\",\n",
            "    \"effective communication\",\n",
            "    \"stakeholder engagement\",\n",
            "    \"team collaboration\"\n",
            "  ],\n",
            "  \"languages\": [\n",
            "    \"English\",\n",
            "    \"Urdu\"\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    \"IBM Machine Learning Specialization Professional Certificate\",\n",
            "    \"Deep Learning Specialization\",\n",
            "    \"Microsoft Azure AI Fundamentals AI-900 Exam Prep Specialization\",\n",
            "    \"Prompt Engineering for ChatGPT\",\n",
            "    \"Machine Learning Engineering for Production (MLOps)\",\n",
            "    \"AI Product Management\",\n",
            "    \"Generative Adversarial Networks (GANs) Specialization\",\n",
            "    \"IBM Generative AI Product Managers\",\n",
            "    \"Preparing for Google Cloud Certification: Machine Learning Engineer\",\n",
            "    \"IBM AI Product Manager\",\n",
            "    \"AWS Cloud Solutions Architect Professional Certificate\",\n",
            "    \"Google Project Management: Professional Certificate\",\n",
            "    \"Practical Data Science on the AWS Cloud Specialization\",\n",
            "    \"Machine Learning Specialization\",\n",
            "    \"MLOps | Machine Learning Operations Specialization\",\n",
            "    \"Advanced Machine Learning on Google Cloud Specialization\",\n",
            "    \"Google Business Intelligence Professional Certificate\",\n",
            "    \"Large Language Model Operations (LLMOps)\",\n",
            "    \"Google Advanced Data Analytics Professional Certificate\"\n",
            "  ],\n",
            "  \"total_experience\": 8.21\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Creating the vector embeddings"
      ],
      "metadata": {
        "id": "ZtkhPep-xT7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class VectorStore:\n",
        "    \"\"\"Manage embeddings and vector similarity search with cosine similarity\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        model_name = embedding_model\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.dimension = self.model.get_sentence_embedding_dimension()\n",
        "\n",
        "    def generate_embedding(self, text: str) -> List[float]:\n",
        "        \"\"\"Generate embedding for text\"\"\"\n",
        "        embedding = self.model.encode(text, normalize_embeddings=True)\n",
        "        return embedding.tolist()\n",
        "\n",
        "    def generate_batch_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Generate embeddings for multiple texts\"\"\"\n",
        "        embeddings = self.model.encode(texts, normalize_embeddings=True, batch_size=32)\n",
        "        return embeddings.tolist()\n",
        "\n",
        "\n",
        "    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:\n",
        "        \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
        "        vec1 = np.array(vec1)\n",
        "        vec2 = np.array(vec2)\n",
        "        return float(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))"
      ],
      "metadata": {
        "id": "b7LH_TvmwhDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = VectorStore()"
      ],
      "metadata": {
        "id": "nhQn3nzHy4NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_json_string = json.dumps(cv_json)\n",
        "cv_embeddings = store.generate_embedding(cv_json_string)"
      ],
      "metadata": {
        "id": "SNoQ_43azIfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv_embeddings)"
      ],
      "metadata": {
        "id": "TaweKqBA2rQU",
        "outputId": "52711800-28a5-42b6-a772-541101cfdae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_json[\"embedding\"] = cv_embeddings"
      ],
      "metadata": {
        "id": "TRosPTwZkdXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Job Recommender"
      ],
      "metadata": {
        "id": "9UIf5OL90OfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JobRecommender:\n",
        "    \"\"\"Match CVs with relevant jobs\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vector_store = VectorStore()\n",
        "\n",
        "    def calculate_skills_match(self, cv_skills: List[str], job_skills: List[str]) -> Dict:\n",
        "        \"\"\"Calculate skill overlap\"\"\"\n",
        "        cv_skills_lower = [s.lower() for s in cv_skills]\n",
        "        job_skills_lower = [s.lower() for s in job_skills]\n",
        "\n",
        "        matched = [s for s in job_skills_lower if s in cv_skills_lower]\n",
        "        missing = [s for s in job_skills_lower if s not in cv_skills_lower]\n",
        "\n",
        "        score = len(matched) / len(job_skills_lower) if job_skills_lower else 0\n",
        "\n",
        "        return {\n",
        "            \"score\": round(score, 3),\n",
        "            \"matched_skills\": matched,\n",
        "            \"missing_skills\": missing\n",
        "        }\n",
        "\n",
        "    def calculate_experience_match(self, candidate_exp: int, required_years) -> float:\n",
        "        \"\"\"Calculate experience match score\"\"\"\n",
        "        min_exp, max_exp = required_years\n",
        "\n",
        "        if max_exp is None:\n",
        "          if candidate_exp >= min_exp:\n",
        "              return 1.0\n",
        "\n",
        "        if min_exp <= candidate_exp <= max_exp:\n",
        "            return 1.0\n",
        "\n",
        "        elif candidate_exp < min_exp:\n",
        "            return max(0, 1 - (min_exp - candidate_exp) / (min_exp))\n",
        "\n",
        "        elif candidate_exp > max_exp:\n",
        "            return max(0, 1 - (candidate_exp - max_exp) / (max_exp))\n",
        "\n",
        "\n",
        "    def calculate_education_match(self, cv_education: List[Dict], required_edu: dict) -> tuple:\n",
        "        \"\"\"Calculate education match with detailed explanation\"\"\"\n",
        "\n",
        "        score = 0.0\n",
        "\n",
        "        lines = []\n",
        "\n",
        "        for edu in cv_education:\n",
        "            institution = edu.get(\"institution\", \"\")\n",
        "            degree = edu.get(\"degree\", \"\")\n",
        "            field = edu.get(\"field\", \"\")\n",
        "            gpa = f\"GPA: {edu['gpa']}\" if edu.get(\"gpa\") else \"\"\n",
        "            start = edu.get(\"startDate\") or \"\"\n",
        "            end = edu.get(\"endDate\") or \"\"\n",
        "            date_range = f\"{start} to {end}\".strip() if start or end else \"\"\n",
        "\n",
        "            line = \" \".join(filter(None, [institution, degree, field, gpa, date_range]))\n",
        "            lines.append(line)\n",
        "\n",
        "        candidate_education = \"\\n\".join(lines)\n",
        "        print(required_edu)\n",
        "        required_degree = required_edu.get(\"required_degree\", \"\")\n",
        "        restriction = required_edu.get(\"degree_restriction\", \"\")\n",
        "        required_field = required_edu.get(\"required_field\", \"\")\n",
        "\n",
        "        job_parts = []\n",
        "\n",
        "        if required_degree:\n",
        "            degree_part = f\"Required Degree {required_degree}\"\n",
        "            if restriction:\n",
        "                degree_part += f\" (Restriction: {restriction})\"\n",
        "            job_parts.append(degree_part)\n",
        "\n",
        "        if required_field:\n",
        "            job_parts.append(f\"Required Field {required_field}\")\n",
        "\n",
        "        job_education = \" \".join(job_parts)\n",
        "\n",
        "        candidate_education_embeddings = self.vector_store.generate_embedding(candidate_education)\n",
        "        job_education_embeddings = self.vector_store.generate_embedding(job_education)\n",
        "\n",
        "        score = self.vector_store.cosine_similarity(candidate_education_embeddings, job_education_embeddings)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def match_cv_to_jobs(self, cv_data: Dict, jobs: List[Dict], top_k: int = 10) -> List[Dict]:\n",
        "        \"\"\"Generate job recommendations for a CV\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        for job in jobs:\n",
        "            semantic_score = self.vector_store.cosine_similarity(\n",
        "                cv_data['embedding'],\n",
        "                job['embedding']\n",
        "            )\n",
        "\n",
        "            skills_match = self.calculate_skills_match(\n",
        "                cv_data.get('skills', []),\n",
        "                job.get('skills', [])\n",
        "            )\n",
        "\n",
        "            cv_years = cv_data.get(\"total_experience\", 0)\n",
        "            exp_score = self.calculate_experience_match(\n",
        "                cv_years,\n",
        "                job.get('experience_years', 0)\n",
        "            )\n",
        "\n",
        "            edu_score = self.calculate_education_match(\n",
        "                cv_data.get('education', []),\n",
        "                job.get('education', '')\n",
        "            )\n",
        "\n",
        "            match_score = (\n",
        "                0.45 * semantic_score +\n",
        "                0.30 * skills_match['score'] +\n",
        "                0.15 * exp_score +\n",
        "                0.10 * edu_score\n",
        "            )\n",
        "\n",
        "            explanation = self._generate_explanation(\n",
        "                match_score, skills_match, cv_years, job.get('experience_years', 0)\n",
        "            )\n",
        "\n",
        "            recommendations.append({\n",
        "                #\"job_id\": job['id'],\n",
        "                \"job_title\": job['title'],\n",
        "                \"company\": job['company'],\n",
        "                \"match_score\": round(match_score, 3),\n",
        "                \"matching_factors\": {\n",
        "                    \"skills_match\": round(skills_match['score'], 3),\n",
        "                    \"experience_match\": round(exp_score, 3),\n",
        "                    \"education_match\": round(edu_score, 3),\n",
        "                    \"semantic_similarity\": round(semantic_score, 3)\n",
        "                },\n",
        "                \"matched_skills\": skills_match['matched_skills'],\n",
        "                \"missing_skills\": skills_match['missing_skills'],\n",
        "                \"explanation\": explanation\n",
        "            })\n",
        "\n",
        "        recommendations.sort(key=lambda x: x['match_score'], reverse=True)\n",
        "        return recommendations[:top_k]\n",
        "\n",
        "    def _generate_explanation(self, match_score: float, skills_match: Dict,\n",
        "                            cv_years: int, required_years: int) -> str:\n",
        "        \"\"\"Generate human-readable explanation\"\"\"\n",
        "        if match_score >= 0.9:\n",
        "            return f\"Excellent match with {len(skills_match['matched_skills'])} matching skills and {cv_years}+ years experience\"\n",
        "        elif match_score >= 0.7:\n",
        "            return f\"Strong match with {len(skills_match['matched_skills'])} core skills aligned\"\n",
        "        else:\n",
        "            return f\"Potential match but may need development in {len(skills_match['missing_skills'])} areas\""
      ],
      "metadata": {
        "id": "xwL2XPMEznf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data\n",
        "job_list = [\n",
        "    {\n",
        "        \"title\": \"Software Developer\",\n",
        "        \"company\": \"TechNova Solutions\",\n",
        "        \"skills\": [\"JavaScript\", \"React\", \"Node.js\", \"Git\", \"Docker\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"Bachelor\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"Computer Science\"\n",
        "        },\n",
        "        \"experience_years\": [2, 4],\n",
        "        \"description\": \"Develop and maintain web applications, collaborate with the design team to build interactive user interfaces, and write clean, scalable code. Strong experience with modern JavaScript frameworks like React and Node.js is required.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"AI Engineer\",\n",
        "        \"company\": \"TechNova Solutions\",\n",
        "        \"skills\": [\"Chroma\", \"LLM\", \"Prompt Engineering\", \"Cloud\",\"Git\", \"PyTorch\", \"Gemini\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"Bachelor\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"Computer Science or related\"\n",
        "        },\n",
        "        \"experience_years\": [4, 6],\n",
        "        \"description\": \"Build and train AI LLM models, collaborate with the team to deploy, write clean and scalable code. Strong experience with modern Python frameworks like numpy and pandas is required.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Marketing Specialist\",\n",
        "        \"company\": \"Creative Media Group\",\n",
        "        \"skills\": [\"SEO\", \"Google Analytics\", \"Content Creation\", \"Social Media Marketing\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"Bachelor\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"Marketing\"\n",
        "        },\n",
        "        \"experience_years\": [1, 3],\n",
        "        \"description\": \"Assist in developing marketing strategies, create and optimize content for various platforms, monitor and analyze marketing data, and work closely with sales teams to enhance brand presence.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Graphic Designer\",\n",
        "        \"company\": \"Artify Studios\",\n",
        "        \"skills\": [\"Adobe Photoshop\", \"Illustrator\", \"Creative Suite\", \"Typography\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"Bachelor\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"Graphic Design\"\n",
        "        },\n",
        "        \"experience_years\": [1, 5],\n",
        "        \"description\": \"Design visual concepts for web, print, and digital media. Work closely with clients and other creative teams to create engaging designs that meet project requirements.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Customer Support Representative\",\n",
        "        \"company\": \"QuickTech Solutions\",\n",
        "        \"skills\": [\"Customer Service\", \"Problem-Solving\", \"Communication\", \"CRM Software\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"High School\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"\"\n",
        "        },\n",
        "        \"experience_years\": [0, 2],\n",
        "        \"description\": \"Provide excellent customer service via phone, email, and chat. Address customer inquiries, troubleshoot technical issues, and escalate concerns as necessary to ensure customer satisfaction.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Project Manager\",\n",
        "        \"company\": \"Global Enterprise Inc.\",\n",
        "        \"skills\": [\"Project Management\", \"Budgeting\", \"Team Leadership\", \"Microsoft Office Suite\"],\n",
        "        \"education\": {\n",
        "            \"required_degree\": \"Bachelor\",\n",
        "            \"degree_restriction\": \"minimum\",\n",
        "            \"required_field\": \"Business Administration\"\n",
        "        },\n",
        "        \"experience_years\": [3, 7],\n",
        "        \"description\": \"Oversee and manage various company projects from inception to completion. Ensure that projects are completed on time, within budget, and according to specifications. Coordinate between multiple teams and stakeholders.\"\n",
        "    }\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "Y4rdwfMd0J7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for job in job_list:\n",
        "  job_json_string = json.dumps(job)\n",
        "  job_embeddings = store.generate_embedding(job_json_string)\n",
        "  job['embedding'] = job_embeddings"
      ],
      "metadata": {
        "id": "Kg9Togt2kxQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_json['skills']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UsdeTf8ol_w",
        "outputId": "78198906-7562-462a-d5da-4af526c34a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python',\n",
              " 'Scikit-Learn',\n",
              " 'TensorFlow',\n",
              " 'Keras',\n",
              " 'PyTorch',\n",
              " 'NLTK',\n",
              " 'Hugging Face Transformers',\n",
              " 'OpenCV',\n",
              " 'FastAPI',\n",
              " 'Flask',\n",
              " 'Streamlit',\n",
              " 'Pandas',\n",
              " 'NumPy',\n",
              " 'Matplotlib',\n",
              " 'Plotly',\n",
              " 'Seaborn',\n",
              " 'PySpark',\n",
              " 'OpenAI API',\n",
              " 'REST APIs',\n",
              " 'GraphQL',\n",
              " 'Neo4j',\n",
              " 'Docker',\n",
              " 'GitHub Actions',\n",
              " 'CI/CD Pipelines',\n",
              " 'SQL',\n",
              " 'NoSQL',\n",
              " 'Vector Databases (Pinecone, Faiss, Chroma DB)',\n",
              " 'Machine Learning',\n",
              " 'Deep Learning',\n",
              " 'Generative AI',\n",
              " 'LLMs (GPT, Gemini, LLaMA, Falcon,DeepSeek)',\n",
              " 'Natural Language Processing (NLP)',\n",
              " 'Time Series Analysis',\n",
              " 'Model Deployment',\n",
              " 'Prompt Engineering',\n",
              " 'LangChain',\n",
              " 'RAG (Retrieval-Augmented Generation)',\n",
              " 'LlamaIndex',\n",
              " 'LangGraph',\n",
              " 'PhiData',\n",
              " 'LangServer',\n",
              " 'AutoGen',\n",
              " 'LangSmith',\n",
              " 'AutoML',\n",
              " 'AI-Driven Process Automation',\n",
              " 'Predictive Modeling',\n",
              " 'Statistical Analysis',\n",
              " 'Big Data Technologies',\n",
              " 'Data Visualization',\n",
              " 'AWS (SageMaker, Lambda, Bedrock, EC2)',\n",
              " 'Azure (Azure ML, Azure AI, App Services)',\n",
              " 'GCP (Vertex AI, Cloud Functions)',\n",
              " 'Heroku',\n",
              " 'MLOps',\n",
              " 'LLMOps',\n",
              " 'AIOps',\n",
              " 'Cloud Machine Learning',\n",
              " 'MLflow',\n",
              " 'Orchestration Frameworks',\n",
              " 'Agile Methodologies',\n",
              " 'Microservices Architecture',\n",
              " 'Business Analysis',\n",
              " 'Product Management',\n",
              " 'Team Leadership',\n",
              " 'Stakeholder Management',\n",
              " 'Business Intelligence',\n",
              " 'technical writing',\n",
              " 'effective communication',\n",
              " 'stakeholder engagement',\n",
              " 'team collaboration']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommender = JobRecommender()"
      ],
      "metadata": {
        "id": "t7Qz-0jFhkTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommender.calculate_experience_match(1, [5, None])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6duSbXDjfKf",
        "outputId": "4894607a-ae38-4ad4-962c-f2b0d80bfedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommender.match_cv_to_jobs(cv_data=cv_json, jobs = job_list)"
      ],
      "metadata": {
        "id": "ZEyrFlhpjjfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fa7ffa-23b4-4ca6-8b6b-64c9be7f0b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'required_degree': 'Bachelor', 'degree_restriction': 'minimum', 'required_field': 'Computer Science'}\n",
            "{'required_degree': 'Bachelor', 'degree_restriction': 'minimum', 'required_field': 'Computer Science or related'}\n",
            "{'required_degree': 'Bachelor', 'degree_restriction': 'minimum', 'required_field': 'Marketing'}\n",
            "{'required_degree': 'Bachelor', 'degree_restriction': 'minimum', 'required_field': 'Graphic Design'}\n",
            "{'required_degree': 'High School', 'degree_restriction': 'minimum', 'required_field': ''}\n",
            "{'required_degree': 'Bachelor', 'degree_restriction': 'minimum', 'required_field': 'Business Administration'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_title': 'AI Engineer',\n",
              "  'company': 'TechNova Solutions',\n",
              "  'match_score': 0.509,\n",
              "  'matching_factors': {'skills_match': 0.286,\n",
              "   'experience_match': 0.632,\n",
              "   'education_match': 0.546,\n",
              "   'semantic_similarity': 0.609},\n",
              "  'matched_skills': ['prompt engineering', 'pytorch'],\n",
              "  'missing_skills': ['chroma', 'llm', 'cloud', 'git', 'gemini'],\n",
              "  'explanation': 'Potential match but may need development in 5 areas'},\n",
              " {'job_title': 'Project Manager',\n",
              "  'company': 'Global Enterprise Inc.',\n",
              "  'match_score': 0.41,\n",
              "  'matching_factors': {'skills_match': 0.25,\n",
              "   'experience_match': 0.827,\n",
              "   'education_match': 0.511,\n",
              "   'semantic_similarity': 0.355},\n",
              "  'matched_skills': ['team leadership'],\n",
              "  'missing_skills': ['project management',\n",
              "   'budgeting',\n",
              "   'microsoft office suite'],\n",
              "  'explanation': 'Potential match but may need development in 3 areas'},\n",
              " {'job_title': 'Software Developer',\n",
              "  'company': 'TechNova Solutions',\n",
              "  'match_score': 0.277,\n",
              "  'matching_factors': {'skills_match': 0.2,\n",
              "   'experience_match': 0,\n",
              "   'education_match': 0.549,\n",
              "   'semantic_similarity': 0.361},\n",
              "  'matched_skills': ['docker'],\n",
              "  'missing_skills': ['javascript', 'react', 'node.js', 'git'],\n",
              "  'explanation': 'Potential match but may need development in 4 areas'},\n",
              " {'job_title': 'Graphic Designer',\n",
              "  'company': 'Artify Studios',\n",
              "  'match_score': 0.256,\n",
              "  'matching_factors': {'skills_match': 0.0,\n",
              "   'experience_match': 0.358,\n",
              "   'education_match': 0.376,\n",
              "   'semantic_similarity': 0.366},\n",
              "  'matched_skills': [],\n",
              "  'missing_skills': ['adobe photoshop',\n",
              "   'illustrator',\n",
              "   'creative suite',\n",
              "   'typography'],\n",
              "  'explanation': 'Potential match but may need development in 4 areas'},\n",
              " {'job_title': 'Marketing Specialist',\n",
              "  'company': 'Creative Media Group',\n",
              "  'match_score': 0.226,\n",
              "  'matching_factors': {'skills_match': 0.0,\n",
              "   'experience_match': 0,\n",
              "   'education_match': 0.445,\n",
              "   'semantic_similarity': 0.403},\n",
              "  'matched_skills': [],\n",
              "  'missing_skills': ['seo',\n",
              "   'google analytics',\n",
              "   'content creation',\n",
              "   'social media marketing'],\n",
              "  'explanation': 'Potential match but may need development in 4 areas'},\n",
              " {'job_title': 'Customer Support Representative',\n",
              "  'company': 'QuickTech Solutions',\n",
              "  'match_score': 0.179,\n",
              "  'matching_factors': {'skills_match': 0.0,\n",
              "   'experience_match': 0,\n",
              "   'education_match': 0.268,\n",
              "   'semantic_similarity': 0.339},\n",
              "  'matched_skills': [],\n",
              "  'missing_skills': ['customer service',\n",
              "   'problem-solving',\n",
              "   'communication',\n",
              "   'crm software'],\n",
              "  'explanation': 'Potential match but may need development in 4 areas'}]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBC5Ngn4lEb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}